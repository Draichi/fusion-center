"""
Graph Nodes for the Deep Research Agent.

Each node represents a step in the research process.
Includes Multi-step Reasoning nodes for deeper analysis.
"""

import json
import uuid
from datetime import datetime
from typing import Any, Literal

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_core.language_models import BaseChatModel

from src.agent.state import AgentState, IntelligenceType, ResearchPhase, HypothesisStatus
from src.agent.tools import MCPToolExecutor, get_tool_definitions, TOOL_NAME_ALIASES, VALID_TOOL_NAMES
from src.agent.prompts import (
    SYSTEM_PROMPT,
    PLANNER_PROMPT,
    ANALYST_PROMPT,
    SYNTHESIZER_PROMPT,
    # Multi-step Reasoning prompts
    TASK_DECOMPOSITION_PROMPT,
    HYPOTHESIS_GENERATION_PROMPT,
    HYPOTHESIS_UPDATE_PROMPT,
    REFLECTION_PROMPT,
    VERIFICATION_PROMPT,
    ENHANCED_ANALYST_PROMPT,
    ENHANCED_SYNTHESIZER_PROMPT,
)
from src.shared.logger import get_logger, log_agent_step
from src.shared.output_writer import get_output_writer

logger = get_logger()


def _resolve_tool_name(tool_name: str) -> str:
    """
    Resolve a tool name to its canonical form, handling aliases.
    
    This ensures that aliased tool names (like 'search_news_by_location')
    are resolved to their actual names (like 'search_news') before
    processing results.
    
    Args:
        tool_name: The tool name, possibly an alias
        
    Returns:
        The resolved canonical tool name
    """
    if tool_name in VALID_TOOL_NAMES:
        return tool_name
    if tool_name in TOOL_NAME_ALIASES:
        return TOOL_NAME_ALIASES[tool_name]
    return tool_name


# =============================================================================
# Helper Functions for Multi-step Reasoning
# =============================================================================


def _add_reasoning_step(
    state: AgentState,
    phase: str,
    thought: str,
    action: str,
    observation: str,
    conclusion: str,
    confidence: float,
) -> dict[str, Any]:
    """Add a reasoning step to the trace."""
    step = {
        "step_number": len(state.get("reasoning_trace", [])) + 1,
        "phase": phase,
        "thought": thought,
        "action": action,
        "observation": observation,
        "conclusion": conclusion,
        "confidence": confidence,
        "timestamp": datetime.utcnow().isoformat(),
    }
    return step


def _extract_thinking_block(response_text: str) -> tuple[str, str]:
    """Extract thinking block from response if present."""
    thinking = ""
    main_response = response_text
    
    if "```thinking" in response_text:
        parts = response_text.split("```thinking")
        if len(parts) > 1:
            thinking_part = parts[1].split("```")[0]
            thinking = thinking_part.strip()
            # Get everything after the thinking block
            remaining = "```".join(parts[1].split("```")[1:])
            main_response = parts[0] + remaining
    
    return thinking, main_response.strip()


# =============================================================================
# Task Decomposition Node (Multi-step Reasoning)
# =============================================================================


async def decompose_task(
    state: AgentState,
    llm: BaseChatModel,
) -> dict[str, Any]:
    """
    Decompose complex tasks into manageable sub-tasks.
    
    This node analyzes task complexity and breaks it down into
    focused sub-tasks that can be investigated independently.
    """
    log_agent_step(state["iteration"] + 1, "Decomposing task into sub-tasks")
    
    writer = get_output_writer()
    writer.log_reasoning(
        phase="decomposing",
        step=state["iteration"] + 1,
        action="Breaking down complex task into sub-tasks",
        details={"task": state["task"]},
    )
    
    decomposition_prompt = f"""
{TASK_DECOMPOSITION_PROMPT}

## Research Task
{state["task"]}

## Context
{json.dumps(state["context"], indent=2) if state["context"] else "No additional context provided."}

Analyze this task and decompose it into sub-tasks.
"""
    
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        HumanMessage(content=decomposition_prompt),
    ]
    
    response = await llm.ainvoke(messages)
    
    try:
        # Extract thinking if present
        thinking, main_response = _extract_thinking_block(response.content)
        
        # Parse JSON response
        if "```json" in main_response:
            main_response = main_response.split("```json")[1].split("```")[0]
        elif "```" in main_response:
            main_response = main_response.split("```")[1].split("```")[0]
        
        result = json.loads(main_response.strip())
        
        # Build sub-tasks
        sub_tasks = []
        for st in result.get("sub_tasks", []):
            sub_tasks.append({
                "id": st.get("id", f"subtask_{len(sub_tasks) + 1}"),
                "description": st.get("description", ""),
                "parent_task": None,
                "status": "pending",
                "findings_ids": [],
                "dependencies": st.get("dependencies", []),
                "focus_area": st.get("focus_area", "thematic"),
                "complexity": st.get("complexity", "moderate"),
            })
        
        task_complexity = result.get("task_complexity", "moderate")
        
        logger.success(f"Task decomposed into {len(sub_tasks)} sub-tasks (complexity: {task_complexity})")
        
        # Log decomposition details
        writer.log_llm_response(
            phase="decomposing",
            prompt_summary=f"Decompose task: {state['task'][:100]}...",
            response=json.dumps(result, indent=2),
        )
        
        if thinking:
            writer.log_reasoning(
                phase="decomposing",
                step=state["iteration"] + 1,
                action="Chain of thought",
                details={"thinking": thinking},
            )
        
        # Add reasoning step
        reasoning_step = _add_reasoning_step(
            state,
            phase="decomposing",
            thought=result.get("decomposition_reasoning", "Task needs to be broken down"),
            action=f"Decomposed into {len(sub_tasks)} sub-tasks",
            observation=f"Identified sub-tasks: {[st['description'][:50] for st in sub_tasks]}",
            conclusion=f"Task complexity: {task_complexity}",
            confidence=0.85,
        )
        
        # Log summary
        summary_lines = [f"[bold]Task Complexity:[/bold] {task_complexity}"]
        for st in sub_tasks[:5]:
            dep_str = f" (deps: {st['dependencies']})" if st['dependencies'] else ""
            summary_lines.append(f"  â€¢ [{st['id']}] {st['description'][:60]}...{dep_str}")
        
        logger.panel("\n".join(summary_lines), title="ðŸ“‹ Task Decomposition", style="blue")
        
        # Determine next phase based on complexity
        next_phase = ResearchPhase.HYPOTHESIZING.value if task_complexity in ["moderate", "complex"] else ResearchPhase.PLANNING.value
        
        return {
            "sub_tasks": sub_tasks,
            "current_sub_task_id": sub_tasks[0]["id"] if sub_tasks else None,
            "task_complexity": task_complexity,
            "reasoning_trace": state.get("reasoning_trace", []) + [reasoning_step],
            "reasoning_depth": state.get("reasoning_depth", 0) + 1,
            "chain_of_thought": state.get("chain_of_thought", []) + [thinking] if thinking else state.get("chain_of_thought", []),
            "current_phase": next_phase,
            "iteration": state["iteration"] + 1,
            "last_updated": datetime.utcnow().isoformat(),
        }
        
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse decomposition: {e}")
        # Fall back to treating as a single task
        return {
            "task_complexity": "simple",
            "current_phase": ResearchPhase.PLANNING.value,
            "iteration": state["iteration"] + 1,
        }


# =============================================================================
# Hypothesis Generation Node (Multi-step Reasoning)
# =============================================================================


async def generate_hypotheses(
    state: AgentState,
    llm: BaseChatModel,
) -> dict[str, Any]:
    """
    Generate testable hypotheses to guide research.
    
    This node forms hypotheses based on the task and existing findings,
    which will guide data gathering and analysis.
    """
    log_agent_step(state["iteration"] + 1, "Generating research hypotheses")
    
    writer = get_output_writer()
    writer.log_reasoning(
        phase="hypothesizing",
        step=state["iteration"] + 1,
        action="Forming testable hypotheses",
        details={
            "task": state["task"],
            "existing_findings": len(state.get("findings", [])),
        },
    )
    
    # Build context from existing findings if any
    findings_summary = ""
    if state.get("findings"):
        findings_summary = f"\n\n## Existing Findings ({len(state['findings'])} total)\n{json.dumps(state['findings'][:10], indent=2)}"
    
    hypothesis_prompt = f"""
{HYPOTHESIS_GENERATION_PROMPT}

## Research Task
{state["task"]}

## Context
{json.dumps(state["context"], indent=2) if state["context"] else "No additional context provided."}

## Sub-tasks (if decomposed)
{json.dumps(state.get("sub_tasks", []), indent=2) if state.get("sub_tasks") else "Task not decomposed."}
{findings_summary}

## Available Tools for Testing Hypotheses
{json.dumps(get_tool_definitions(), indent=2)}

Generate hypotheses that can be tested with these tools.
"""
    
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        HumanMessage(content=hypothesis_prompt),
    ]
    
    response = await llm.ainvoke(messages)
    
    try:
        thinking, main_response = _extract_thinking_block(response.content)
        
        if "```json" in main_response:
            main_response = main_response.split("```json")[1].split("```")[0]
        elif "```" in main_response:
            main_response = main_response.split("```")[1].split("```")[0]
        
        result = json.loads(main_response.strip())
        
        # Build hypotheses
        hypotheses = []
        test_queries = []
        
        for h in result.get("hypotheses", []):
            hypothesis = {
                "id": h.get("id", f"h{len(hypotheses) + 1}"),
                "statement": h.get("statement", ""),
                "status": HypothesisStatus.PROPOSED.value,
                "confidence": h.get("initial_confidence", 0.5),
                "supporting_evidence": [],
                "contradicting_evidence": [],
                "reasoning": "",
                "supporting_criteria": h.get("supporting_evidence_criteria", []),
                "refuting_criteria": h.get("refuting_evidence_criteria", []),
                "created_at": datetime.utcnow().isoformat(),
                "updated_at": datetime.utcnow().isoformat(),
            }
            hypotheses.append(hypothesis)
            
            # Collect test queries for this hypothesis
            for q in h.get("test_queries", []):
                q["hypothesis_id"] = hypothesis["id"]
                test_queries.append(q)
        
        logger.success(f"Generated {len(hypotheses)} hypotheses with {len(test_queries)} test queries")
        
        # Log response
        writer.log_llm_response(
            phase="hypothesizing",
            prompt_summary="Generate research hypotheses",
            response=json.dumps(result, indent=2),
        )
        
        # Log reasoning chain
        reasoning_chain = result.get("reasoning_chain", [])
        if reasoning_chain:
            writer.log_reasoning(
                phase="hypothesizing",
                step=state["iteration"] + 1,
                action="Reasoning chain",
                details={"chain": reasoning_chain},
            )
        
        # Add reasoning step
        reasoning_step = _add_reasoning_step(
            state,
            phase="hypothesizing",
            thought="\n".join(reasoning_chain) if reasoning_chain else "Forming hypotheses for investigation",
            action=f"Generated {len(hypotheses)} hypotheses",
            observation=f"Hypotheses: {[h['statement'][:50] for h in hypotheses]}",
            conclusion=f"Ready to test with {len(test_queries)} queries",
            confidence=0.7,
        )
        
        # Log summary
        summary_lines = ["[bold]Hypotheses:[/bold]"]
        for h in hypotheses:
            conf_bar = "â–ˆ" * int(h["confidence"] * 10) + "â–‘" * (10 - int(h["confidence"] * 10))
            summary_lines.append(f"  [{h['id']}] {h['statement'][:60]}...")
            summary_lines.append(f"      Confidence: [{conf_bar}] {h['confidence']:.0%}")
        
        logger.panel("\n".join(summary_lines), title="ðŸ”¬ Research Hypotheses", style="cyan")
        
        return {
            "hypotheses": state.get("hypotheses", []) + hypotheses,
            "active_hypothesis_id": hypotheses[0]["id"] if hypotheses else None,
            "pending_queries": test_queries[:5],  # Start with first 5 test queries
            "reasoning_trace": state.get("reasoning_trace", []) + [reasoning_step],
            "reasoning_depth": state.get("reasoning_depth", 0) + 1,
            "chain_of_thought": state.get("chain_of_thought", []) + reasoning_chain,
            "current_phase": ResearchPhase.GATHERING.value,
            "iteration": state["iteration"] + 1,
            "last_updated": datetime.utcnow().isoformat(),
        }
        
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse hypotheses: {e}")
        return {
            "current_phase": ResearchPhase.PLANNING.value,
            "iteration": state["iteration"] + 1,
        }


# =============================================================================
# Hypothesis Update Node (Multi-step Reasoning)
# =============================================================================


async def update_hypotheses(
    state: AgentState,
    llm: BaseChatModel,
) -> dict[str, Any]:
    """
    Update hypothesis confidence based on new evidence.
    
    This node performs Bayesian-style updates to hypothesis
    confidence based on gathered findings.
    """
    log_agent_step(state["iteration"] + 1, "Updating hypotheses with new evidence")
    
    writer = get_output_writer()
    
    hypotheses = state.get("hypotheses", [])
    findings = state.get("findings", [])
    
    if not hypotheses or not findings:
        logger.info("No hypotheses or findings to update")
        return {
            "current_phase": ResearchPhase.ANALYZING.value,
            "iteration": state["iteration"] + 1,
        }
    
    writer.log_reasoning(
        phase="hypothesizing",
        step=state["iteration"] + 1,
        action="Updating hypotheses based on evidence",
        details={
            "num_hypotheses": len(hypotheses),
            "num_findings": len(findings),
        },
    )
    
    update_prompt = f"""
{HYPOTHESIS_UPDATE_PROMPT}

## Current Hypotheses
{json.dumps(hypotheses, indent=2)}

## New Findings
{json.dumps(findings[-20:], indent=2)}  # Last 20 findings

Review each finding and update hypothesis confidence accordingly.
"""
    
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        HumanMessage(content=update_prompt),
    ]
    
    response = await llm.ainvoke(messages)
    
    try:
        thinking, main_response = _extract_thinking_block(response.content)
        
        if "```json" in main_response:
            main_response = main_response.split("```json")[1].split("```")[0]
        elif "```" in main_response:
            main_response = main_response.split("```")[1].split("```")[0]
        
        result = json.loads(main_response.strip())
        
        # Update hypotheses
        updated_hypotheses = {h["id"]: h.copy() for h in hypotheses}
        
        for update in result.get("hypothesis_updates", []):
            h_id = update.get("hypothesis_id")
            if h_id in updated_hypotheses:
                h = updated_hypotheses[h_id]
                h["confidence"] = update.get("new_confidence", h["confidence"])
                h["status"] = update.get("new_status", h["status"])
                h["supporting_evidence"].extend(update.get("new_supporting_evidence", []))
                h["contradicting_evidence"].extend(update.get("new_contradicting_evidence", []))
                h["reasoning"] = update.get("confidence_change_reason", "")
                h["updated_at"] = datetime.utcnow().isoformat()
        
        updated_list = list(updated_hypotheses.values())
        
        # Log response
        writer.log_llm_response(
            phase="hypothesizing",
            prompt_summary="Update hypotheses with evidence",
            response=json.dumps(result, indent=2),
        )
        
        # Add reasoning step
        reasoning_chain = result.get("reasoning_chain", [])
        reasoning_step = _add_reasoning_step(
            state,
            phase="hypothesis_update",
            thought="\n".join(reasoning_chain) if reasoning_chain else "Evaluating evidence against hypotheses",
            action="Updated hypothesis confidence scores",
            observation=f"Updates: {len(result.get('hypothesis_updates', []))}",
            conclusion="Hypotheses updated based on evidence",
            confidence=0.8,
        )
        
        # Log summary
        summary_lines = ["[bold]Hypothesis Updates:[/bold]"]
        for h in updated_list:
            status_emoji = {
                "supported": "âœ…",
                "refuted": "âŒ",
                "investigating": "ðŸ”",
                "inconclusive": "â“",
                "proposed": "ðŸ“",
            }.get(h["status"], "ðŸ“")
            conf_bar = "â–ˆ" * int(h["confidence"] * 10) + "â–‘" * (10 - int(h["confidence"] * 10))
            summary_lines.append(f"  {status_emoji} [{h['id']}] {h['statement'][:50]}...")
            summary_lines.append(f"      Confidence: [{conf_bar}] {h['confidence']:.0%}")
        
        logger.panel("\n".join(summary_lines), title="ðŸ“Š Hypothesis Status", style="yellow")
        
        return {
            "hypotheses": updated_list,
            "reasoning_trace": state.get("reasoning_trace", []) + [reasoning_step],
            "chain_of_thought": state.get("chain_of_thought", []) + reasoning_chain,
            "current_phase": ResearchPhase.ANALYZING.value,
            "iteration": state["iteration"] + 1,
            "last_updated": datetime.utcnow().isoformat(),
        }
        
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse hypothesis updates: {e}")
        return {
            "current_phase": ResearchPhase.ANALYZING.value,
            "iteration": state["iteration"] + 1,
        }


# =============================================================================
# Reflection Node (Multi-step Reasoning)
# =============================================================================


async def reflect_on_analysis(
    state: AgentState,
    llm: BaseChatModel,
) -> dict[str, Any]:
    """
    Perform critical self-reflection on the analysis.
    
    This node identifies biases, gaps, alternative explanations,
    and calibrates confidence levels.
    """
    log_agent_step(state["iteration"] + 1, "Self-reflection on analysis")
    
    writer = get_output_writer()
    writer.log_reasoning(
        phase="reflecting",
        step=state["iteration"] + 1,
        action="Critical self-examination of analysis",
        details={
            "insights_count": len(state.get("key_insights", [])),
            "hypotheses_count": len(state.get("hypotheses", [])),
            "reflection_iteration": state.get("reflection_iterations", 0) + 1,
        },
    )
    
    reflection_prompt = f"""
{REFLECTION_PROMPT}

## Original Task
{state["task"]}

## Current Hypotheses
{json.dumps(state.get("hypotheses", []), indent=2)}

## Key Insights So Far
{json.dumps(state.get("key_insights", []), indent=2)}

## Correlations Found
{json.dumps(state.get("correlations", []), indent=2)}

## Uncertainties Identified
{json.dumps(state.get("uncertainties", []), indent=2)}

## Available Tools for Additional Investigation
{json.dumps([t["name"] for t in get_tool_definitions()], indent=2)}

Critically reflect on this analysis. Be thorough but constructive.
"""
    
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        HumanMessage(content=reflection_prompt),
    ]
    
    response = await llm.ainvoke(messages)
    
    try:
        thinking, main_response = _extract_thinking_block(response.content)
        
        if "```json" in main_response:
            main_response = main_response.split("```json")[1].split("```")[0]
        elif "```" in main_response:
            main_response = main_response.split("```")[1].split("```")[0]
        
        result = json.loads(main_response.strip())
        
        # Build reflection notes
        reflection_notes = []
        for note in result.get("reflection_notes", []):
            reflection_notes.append({
                "category": note.get("category", "gap_analysis"),
                "content": note.get("content", ""),
                "severity": note.get("severity", "info"),
                "action_required": note.get("action_required", False),
                "suggested_action": note.get("suggested_action"),
                "timestamp": datetime.utcnow().isoformat(),
            })
        
        needs_investigation = result.get("needs_more_investigation", False)
        investigation_queries = result.get("investigation_suggestions", [])
        
        # Log response
        writer.log_llm_response(
            phase="reflecting",
            prompt_summary="Self-reflection on analysis",
            response=json.dumps(result, indent=2),
        )
        
        # Add reasoning step
        reflection_chain = result.get("reflection_chain", [])
        reasoning_step = _add_reasoning_step(
            state,
            phase="reflecting",
            thought="\n".join(reflection_chain) if reflection_chain else "Examining analysis for biases and gaps",
            action=f"Generated {len(reflection_notes)} reflection notes",
            observation=f"Critical issues: {sum(1 for n in reflection_notes if n['severity'] == 'critical')}",
            conclusion="Needs more investigation" if needs_investigation else "Analysis is robust",
            confidence=0.75,
        )
        
        # Log summary with severity-based formatting
        summary_lines = ["[bold]Reflection Results:[/bold]"]
        severity_counts = {"info": 0, "warning": 0, "critical": 0}
        
        for note in reflection_notes:
            severity_counts[note["severity"]] = severity_counts.get(note["severity"], 0) + 1
            emoji = {"info": "â„¹ï¸", "warning": "âš ï¸", "critical": "ðŸš¨"}.get(note["severity"], "ðŸ“")
            summary_lines.append(f"  {emoji} [{note['category']}] {note['content'][:60]}...")
            if note["action_required"] and note["suggested_action"]:
                summary_lines.append(f"      â†’ Action: {note['suggested_action'][:50]}...")
        
        summary_lines.append(f"\n[bold]Summary:[/bold] {severity_counts['critical']} critical, {severity_counts['warning']} warnings, {severity_counts['info']} info")
        
        style = "red" if severity_counts["critical"] > 0 else "yellow" if severity_counts["warning"] > 0 else "green"
        logger.panel("\n".join(summary_lines), title="ðŸªž Self-Reflection", style=style)
        
        # Determine next phase
        if needs_investigation and investigation_queries and state.get("reflection_iterations", 0) < 2:
            next_phase = ResearchPhase.GATHERING.value
            pending = investigation_queries[:3]
        elif any(n["severity"] == "critical" and n["action_required"] for n in reflection_notes):
            next_phase = ResearchPhase.ANALYZING.value
            pending = state.get("pending_queries", [])
        else:
            next_phase = ResearchPhase.CORRELATING.value
            pending = state.get("pending_queries", [])
        
        return {
            "reflection_notes": state.get("reflection_notes", []) + reflection_notes,
            "reflection_iterations": state.get("reflection_iterations", 0) + 1,
            "needs_more_reflection": needs_investigation,
            "pending_queries": pending,
            "reasoning_trace": state.get("reasoning_trace", []) + [reasoning_step],
            "chain_of_thought": state.get("chain_of_thought", []) + reflection_chain,
            "current_phase": next_phase,
            "iteration": state["iteration"] + 1,
            "last_updated": datetime.utcnow().isoformat(),
        }
        
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse reflection: {e}")
        return {
            "current_phase": ResearchPhase.CORRELATING.value,
            "iteration": state["iteration"] + 1,
        }


# =============================================================================
# Verification Node (Multi-step Reasoning)
# =============================================================================


async def verify_conclusions(
    state: AgentState,
    llm: BaseChatModel,
) -> dict[str, Any]:
    """
    Verify consistency and validity of conclusions.
    
    This node performs final checks before synthesis to ensure
    conclusions are supported by evidence and internally consistent.
    """
    log_agent_step(state["iteration"] + 1, "Verifying conclusions")
    
    writer = get_output_writer()
    writer.log_reasoning(
        phase="verifying",
        step=state["iteration"] + 1,
        action="Verifying consistency of conclusions",
        details={
            "insights_to_verify": len(state.get("key_insights", [])),
            "correlations_to_verify": len(state.get("correlations", [])),
        },
    )
    
    verification_prompt = f"""
{VERIFICATION_PROMPT}

## Original Task
{state["task"]}

## Findings (Evidence Base)
{json.dumps(state.get("findings", [])[:30], indent=2)}

## Hypotheses and Their Status
{json.dumps(state.get("hypotheses", []), indent=2)}

## Key Insights to Verify
{json.dumps(state.get("key_insights", []), indent=2)}

## Correlations to Verify
{json.dumps(state.get("correlations", []), indent=2)}

Verify each conclusion against the evidence.
"""
    
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        HumanMessage(content=verification_prompt),
    ]
    
    response = await llm.ainvoke(messages)
    
    try:
        thinking, main_response = _extract_thinking_block(response.content)
        
        if "```json" in main_response:
            main_response = main_response.split("```json")[1].split("```")[0]
        elif "```" in main_response:
            main_response = main_response.split("```")[1].split("```")[0]
        
        result = json.loads(main_response.strip())
        
        # Process verification results
        verification_results = []
        verified_insights = []
        verified_correlations = []
        
        # Process insight verifications
        for iv in result.get("insight_verifications", []):
            verification_results.append({
                "item_type": "insight",
                "item_id": iv.get("insight_index", 0),
                "is_consistent": iv.get("verdict") in ["pass", "adjust"],
                "issues_found": iv.get("issues", []),
                "confidence_adjustment": 0.0 if iv.get("verdict") == "pass" else -0.1,
                "verification_notes": iv.get("evidence_check", ""),
            })
            
            if iv.get("verdict") in ["pass", "adjust"]:
                # Use revised insight if available, otherwise original
                insight_text = iv.get("revised_insight") or iv.get("original_insight", "")
                if insight_text:
                    verified_insights.append(insight_text)
        
        # Process correlation verifications
        for cv in result.get("correlation_verifications", []):
            verification_results.append({
                "item_type": "correlation",
                "item_id": cv.get("correlation_index", 0),
                "is_consistent": cv.get("verdict") in ["pass", "adjust"],
                "issues_found": cv.get("issues", []),
                "confidence_adjustment": 0.0,
                "verification_notes": f"Temporal: {cv.get('temporal_check', 'N/A')}, Spatial: {cv.get('spatial_check', 'N/A')}",
            })
            
            if cv.get("verdict") in ["pass", "adjust"]:
                # Get the original correlation and update its confidence
                corr_idx = cv.get("correlation_index", 0)
                correlations = state.get("correlations", [])
                if corr_idx < len(correlations):
                    verified_corr = correlations[corr_idx].copy()
                    verified_corr["confidence"] = cv.get("suggested_confidence", verified_corr.get("confidence", "medium"))
                    verified_correlations.append(verified_corr)
        
        # Log response
        writer.log_llm_response(
            phase="verifying",
            prompt_summary="Verify conclusions before synthesis",
            response=json.dumps(result, indent=2),
        )
        
        # Add reasoning step
        verification_chain = result.get("verification_chain", [])
        overall = result.get("overall_assessment", {})
        
        reasoning_step = _add_reasoning_step(
            state,
            phase="verifying",
            thought="\n".join(verification_chain) if verification_chain else "Verifying all conclusions",
            action=f"Verified {len(verification_results)} items",
            observation=f"Passed: {sum(1 for v in verification_results if v['is_consistent'])}, Failed: {sum(1 for v in verification_results if not v['is_consistent'])}",
            conclusion="Ready for synthesis" if overall.get("ready_for_synthesis") else "Issues need addressing",
            confidence=0.85,
        )
        
        # Log summary
        passed = sum(1 for v in verification_results if v["is_consistent"])
        failed = len(verification_results) - passed
        
        summary_lines = [
            f"[bold]Verification Results:[/bold]",
            f"  âœ… Passed: {passed}",
            f"  âŒ Failed/Flagged: {failed}",
            f"  ðŸ“ Verified Insights: {len(verified_insights)}",
            f"  ðŸ”— Verified Correlations: {len(verified_correlations)}",
        ]
        
        if overall.get("critical_issues"):
            summary_lines.append("\n[bold]Critical Issues:[/bold]")
            for issue in overall["critical_issues"][:3]:
                summary_lines.append(f"  ðŸš¨ {issue}")
        
        style = "green" if overall.get("ready_for_synthesis") else "yellow"
        logger.panel("\n".join(summary_lines), title="âœ“ Verification Complete", style=style)
        
        # Determine next phase
        next_phase = ResearchPhase.SYNTHESIZING.value if overall.get("ready_for_synthesis", True) else ResearchPhase.REFLECTING.value
        
        return {
            "verification_results": state.get("verification_results", []) + verification_results,
            "verified_insights": verified_insights if verified_insights else state.get("key_insights", []),
            "verified_correlations": verified_correlations if verified_correlations else state.get("correlations", []),
            "reasoning_trace": state.get("reasoning_trace", []) + [reasoning_step],
            "chain_of_thought": state.get("chain_of_thought", []) + verification_chain,
            "current_phase": next_phase,
            "iteration": state["iteration"] + 1,
            "last_updated": datetime.utcnow().isoformat(),
        }
        
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse verification: {e}")
        return {
            "verified_insights": state.get("key_insights", []),
            "verified_correlations": state.get("correlations", []),
            "current_phase": ResearchPhase.SYNTHESIZING.value,
            "iteration": state["iteration"] + 1,
        }


# =============================================================================
# Planning Node
# =============================================================================


async def plan_research(
    state: AgentState,
    llm: BaseChatModel,
) -> dict[str, Any]:
    """
    Plan the research approach based on the task.
    
    This node analyzes the task and creates a structured research plan
    including regions, keywords, and data sources to query.
    """
    log_agent_step(state["iteration"] + 1, "Planning research approach")
    
    # Log to reasoning file
    writer = get_output_writer()
    writer.log_reasoning(
        phase="planning",
        step=state["iteration"] + 1,
        action="Creating research plan",
        details={"task": state["task"], "context": state.get("context")},
    )
    
    planning_prompt = f"""
{PLANNER_PROMPT}

## Task
{state["task"]}

## Context
{json.dumps(state["context"], indent=2) if state["context"] else "No additional context provided."}

## Available Tools
{json.dumps(get_tool_definitions(), indent=2)}

Create a research plan as JSON with this structure:
{{
    "objectives": ["objective 1", "objective 2"],
    "regions_of_interest": ["Ukraine", "Russia"],
    "keywords": ["military", "strike", "drone"],
    "coordinates": [{{"lat": 50.45, "lon": 30.52, "radius_km": 100}}],
    "time_range": "7d",
    "priority_sources": ["news", "satellite", "cyber"],
    "initial_queries": [
        {{"tool": "search_news", "args": {{"keywords": "...", "country_code": "..."}}}},
        ...
    ]
}}

Respond ONLY with the JSON, no other text.
"""
    
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        HumanMessage(content=planning_prompt),
    ]
    
    response = await llm.ainvoke(messages)
    
    try:
        # Parse the research plan
        plan_text = response.content
        # Clean up potential markdown code blocks
        if "```json" in plan_text:
            plan_text = plan_text.split("```json")[1].split("```")[0]
        elif "```" in plan_text:
            plan_text = plan_text.split("```")[1].split("```")[0]
        
        plan = json.loads(plan_text.strip())
        
        # Log the research plan details
        logger.success(f"Research plan created with {len(plan.get('initial_queries', []))} initial queries")
        
        # Log LLM response to reasoning file
        writer.log_llm_response(
            phase="planning",
            prompt_summary=f"Create research plan for: {state['task'][:100]}...",
            response=json.dumps(plan, indent=2),
        )
        
        # Show plan details
        plan_summary = []
        if plan.get("objectives"):
            plan_summary.append(f"[bold]Objectives:[/bold] {len(plan['objectives'])}")
            for obj in plan["objectives"][:3]:
                plan_summary.append(f"  â€¢ {obj}")
        if plan.get("regions_of_interest"):
            plan_summary.append(f"[bold]Regions:[/bold] {', '.join(plan['regions_of_interest'][:5])}")
        if plan.get("keywords"):
            plan_summary.append(f"[bold]Keywords:[/bold] {', '.join(plan['keywords'][:5])}")
        if plan.get("priority_sources"):
            plan_summary.append(f"[bold]Data Sources:[/bold] {', '.join(plan['priority_sources'])}")
        if plan.get("initial_queries"):
            plan_summary.append(f"[bold]Planned Queries:[/bold]")
            for q in plan["initial_queries"][:5]:
                plan_summary.append(f"  â€¢ {q.get('tool')}({', '.join(f'{k}={v}' for k,v in q.get('args', {}).items())})")
        
        logger.panel("\n".join(plan_summary), title="ðŸ“‹ Research Plan", style="cyan")
        
        # Add reasoning step for planning
        reasoning_step = _add_reasoning_step(
            state,
            phase="planning",
            thought=f"Planning research approach for: {state['task'][:100]}",
            action="Created comprehensive research plan",
            observation=f"Planned {len(plan.get('initial_queries', []))} initial queries across {len(plan.get('priority_sources', []))} sources",
            conclusion="Ready to proceed with task decomposition",
            confidence=0.8,
        )
        
        # Start with task decomposition for multi-step reasoning
        # This allows the agent to break down complex tasks before gathering
        return {
            "research_plan": plan,
            "pending_queries": plan.get("initial_queries", []),
            "current_phase": ResearchPhase.DECOMPOSING.value,  # Start with decomposition
            "iteration": state["iteration"] + 1,
            "reasoning_trace": state.get("reasoning_trace", []) + [reasoning_step],
            "reasoning_depth": state.get("reasoning_depth", 0) + 1,
            "last_updated": datetime.utcnow().isoformat(),
            "messages": [
                HumanMessage(content=state["task"]),
                AIMessage(content=f"Research plan created: {json.dumps(plan, indent=2)}"),
            ],
        }
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse research plan: {e}")
        return {
            "error": f"Failed to parse research plan: {e}",
            "current_phase": ResearchPhase.COMPLETE.value,
        }


# =============================================================================
# Data Gathering Node
# =============================================================================


async def gather_intelligence(
    state: AgentState,
    tool_executor: MCPToolExecutor,
) -> dict[str, Any]:
    """
    Execute pending queries to gather intelligence.
    
    This node executes the planned queries against the MCP server
    and collects the results as findings.
    """
    log_agent_step(state["iteration"] + 1, "Gathering intelligence data")
    
    # Log to reasoning file
    writer = get_output_writer()
    writer.log_reasoning(
        phase="gathering",
        step=state["iteration"] + 1,
        action="Executing intelligence queries",
        details={"pending_queries_count": len(state.get("pending_queries", []))},
    )
    
    pending = state.get("pending_queries", [])
    if not pending:
        logger.info("No pending queries to execute")
        return {
            "current_phase": ResearchPhase.ANALYZING.value,
            "iteration": state["iteration"] + 1,
            "last_updated": datetime.utcnow().isoformat(),
        }
    
    new_findings = []
    executed = []
    
    # Execute up to 5 queries per iteration to avoid overload
    queries_to_run = pending[:5]
    remaining = pending[5:]
    
    for query in queries_to_run:
        tool_name = query.get("tool")
        args = query.get("args", {})
        
        # Resolve tool name to handle aliases (e.g., search_news_by_location -> search_news)
        resolved_tool_name = _resolve_tool_name(tool_name)
        
        logger.info(f"Executing query: [bold]{tool_name}[/bold]")
        
        result = await tool_executor.execute(tool_name, args)
        
        executed.append({
            "tool": tool_name,
            "args": args,
            "timestamp": datetime.utcnow().isoformat(),
        })
        
        # Process results into findings using resolved name for proper extraction
        if result.get("status") == "success" or result.get("status") == "stub":
            findings = _extract_findings(resolved_tool_name, args, result)
            new_findings.extend(findings)
            logger.success(f"Extracted {len(findings)} findings from {tool_name}")
            
            # Log to reasoning file
            writer.log_tool_execution(
                tool_name=tool_name,
                args=args,
                result_summary=f"Extracted {len(findings)} findings",
                success=True,
            )
            
            # Log brief result summary using resolved name
            _log_tool_result_summary(resolved_tool_name, result)
        else:
            error_msg = result.get("error_message") or result.get("error", "Unknown error")
            logger.warning(f"Query returned error: {error_msg}")
            
            # Log failed tool execution
            writer.log_tool_execution(
                tool_name=tool_name,
                args=args,
                result_summary=f"Error: {error_msg}",
                success=False,
            )
    
    all_findings = state.get("findings", []) + new_findings
    all_executed = state.get("executed_queries", []) + executed
    
    # Determine next phase
    next_phase = ResearchPhase.GATHERING.value if remaining else ResearchPhase.ANALYZING.value
    
    return {
        "findings": all_findings,
        "executed_queries": all_executed,
        "pending_queries": remaining,
        "current_phase": next_phase,
        "iteration": state["iteration"] + 1,
        "last_updated": datetime.utcnow().isoformat(),
    }


def _log_tool_result_summary(tool_name: str, result: dict[str, Any]) -> None:
    """Log a brief summary of tool results."""
    summary_lines = []
    
    if tool_name == "search_news":
        articles = result.get("articles", [])
        if articles:
            summary_lines.append(f"[bold]Found {len(articles)} articles:[/bold]")
            for article in articles[:3]:
                title = article.get("title", "No title")[:60]
                source = article.get("domain", "unknown")
                summary_lines.append(f"  â€¢ [{source}] {title}...")
    
    elif tool_name == "detect_thermal_anomalies":
        count = result.get("anomaly_count", 0)
        if count > 0:
            summary_lines.append(f"[bold]Detected {count} thermal anomalies[/bold]")
            anomalies = result.get("anomalies", [])[:3]
            for a in anomalies:
                summary_lines.append(
                    f"  â€¢ ({a.get('latitude'):.2f}, {a.get('longitude'):.2f}) "
                    f"brightness={a.get('brightness')} conf={a.get('confidence')}"
                )
    
    elif tool_name == "check_connectivity":
        status = result.get("current_status", {})
        if status:
            summary_lines.append(f"[bold]Connectivity Status:[/bold] {status.get('status', 'unknown')}")
            if status.get("bgp_visibility"):
                summary_lines.append(f"  â€¢ BGP Visibility: {status['bgp_visibility']:.1f}%")
        outages = result.get("recent_outages", [])
        if outages:
            summary_lines.append(f"  â€¢ Recent outages: {len(outages)}")
    
    elif tool_name in ["search_sanctions", "screen_entity"]:
        entities = result.get("entities", [])
        if entities:
            summary_lines.append(f"[bold]Found {len(entities)} sanctioned entities[/bold]")
            for e in entities[:3]:
                summary_lines.append(f"  â€¢ {e.get('name')} ({e.get('entity_type')})")
    
    if summary_lines:
        logger.panel("\n".join(summary_lines), title=f"ðŸ“¥ {tool_name} Results", style="dim cyan")


def _extract_findings(
    tool_name: str,
    args: dict[str, Any],
    result: dict[str, Any],
) -> list[dict[str, Any]]:
    """Extract structured findings from tool results."""
    findings = []
    timestamp = datetime.utcnow().isoformat()
    
    if tool_name == "search_news":
        articles = result.get("articles", [])
        for article in articles[:10]:  # Limit to top 10
            findings.append({
                "source": article.get("domain", "unknown"),
                "source_type": IntelligenceType.NEWS.value,
                "timestamp": timestamp,
                "content": {
                    "title": article.get("title"),
                    "url": article.get("url"),
                    "date": article.get("seendate"),
                    "country": article.get("sourcecountry"),
                },
                "relevance_score": 0.8,
                "confidence": "medium",
            })
    
    
    elif tool_name == "detect_thermal_anomalies":
        anomalies = result.get("anomalies", [])
        for anomaly in anomalies[:20]:
            findings.append({
                "source": "NASA FIRMS",
                "source_type": IntelligenceType.SATELLITE.value,
                "timestamp": timestamp,
                "content": {
                    "brightness": anomaly.get("brightness"),
                    "confidence": anomaly.get("confidence"),
                    "acq_date": anomaly.get("acq_date"),
                    "acq_time": anomaly.get("acq_time"),
                    "frp": anomaly.get("frp"),
                },
                "location": {
                    "lat": anomaly.get("latitude"),
                    "lon": anomaly.get("longitude"),
                },
                "relevance_score": 0.95,
                "confidence": anomaly.get("confidence", "nominal"),
            })
    
    elif tool_name == "check_connectivity":
        status = result.get("current_status", {})
        outages = result.get("recent_outages", [])
        
        if status:
            findings.append({
                "source": "IODA",
                "source_type": IntelligenceType.CYBER.value,
                "timestamp": timestamp,
                "content": {
                    "region": status.get("region"),
                    "status": status.get("status"),
                    "bgp_visibility": status.get("bgp_visibility"),
                },
                "relevance_score": 0.85,
                "confidence": "high",
            })
        
        for outage in outages:
            findings.append({
                "source": "IODA",
                "source_type": IntelligenceType.CYBER.value,
                "timestamp": timestamp,
                "content": {
                    "region": outage.get("region"),
                    "severity": outage.get("severity"),
                    "start_time": outage.get("start_time"),
                },
                "relevance_score": 0.9,
                "confidence": "high",
            })
    
    elif tool_name == "search_sanctions":
        entities = result.get("entities", [])
        for entity in entities:
            findings.append({
                "source": "OpenSanctions",
                "source_type": IntelligenceType.SANCTIONS.value,
                "timestamp": timestamp,
                "content": {
                    "name": entity.get("name"),
                    "entity_type": entity.get("entity_type"),
                    "countries": entity.get("countries"),
                    "sanctions_lists": entity.get("sanctions_lists"),
                },
                "relevance_score": entity.get("match_score", 0.8),
                "confidence": "high" if entity.get("match_score", 0) > 0.9 else "medium",
            })
    
    return findings


# =============================================================================
# Analysis Node
# =============================================================================


async def analyze_findings(
    state: AgentState,
    llm: BaseChatModel,
) -> dict[str, Any]:
    """
    Analyze collected findings and extract insights.
    
    This node uses the LLM to analyze the gathered intelligence
    and identify key patterns and insights. Uses Chain-of-Thought
    reasoning for deeper analysis.
    """
    log_agent_step(state["iteration"] + 1, "Analyzing findings")
    
    # Log to reasoning file
    writer = get_output_writer()
    writer.log_reasoning(
        phase="analyzing",
        step=state["iteration"] + 1,
        action="Analyzing collected findings with multi-step reasoning",
        details={
            "findings_count": len(state.get("findings", [])),
            "hypotheses_count": len(state.get("hypotheses", [])),
        },
    )
    
    findings = state.get("findings", [])
    if not findings:
        logger.warning("No findings to analyze")
        return {
            "current_phase": ResearchPhase.SYNTHESIZING.value,
            "iteration": state["iteration"] + 1,
        }
    
    # Get available tools for the prompt
    available_tools = get_tool_definitions()
    tool_names = [t["name"] for t in available_tools]
    
    # Use enhanced analyst prompt for multi-step reasoning
    analysis_prompt = f"""
{ENHANCED_ANALYST_PROMPT}

## Original Task
{state["task"]}

## Current Hypotheses
{json.dumps(state.get("hypotheses", []), indent=2) if state.get("hypotheses") else "No hypotheses generated yet."}

## Collected Findings ({len(findings)} total)
{json.dumps(findings[:30], indent=2)}  # Limit to 30 for context window

## Available Tools for Follow-up Queries
You can ONLY use these tool names for follow_up_queries:
{json.dumps(tool_names, indent=2)}

Tool details:
{json.dumps(available_tools, indent=2)}

## Instructions
Think step by step:
1. First, survey all the evidence - what types of data do we have?
2. What patterns emerge from individual sources?
3. How does this evidence relate to our hypotheses?
4. What areas still need investigation?

Then provide your analysis with:
1. Key patterns observed (with evidence citations)
2. Notable events or anomalies
3. Preliminary correlations between different data sources
4. How findings support/refute each hypothesis
5. Confidence assessment for each insight
6. Areas requiring further investigation

IMPORTANT: For follow_up_queries, you MUST use one of the exact tool names listed above.
Do NOT use data source names like "GDELT" or "IODA" - use the actual tool names like "search_news" or "check_connectivity".

Respond as JSON:
{{
    "thinking": "Your step-by-step reasoning process...",
    "key_insights": ["insight 1", "insight 2"],
    "hypothesis_implications": [
        {{"hypothesis_id": "h1", "evidence_type": "supporting|contradicting|neutral", "explanation": "..."}}
    ],
    "correlations": [
        {{
            "finding_ids": [0, 5],
            "correlation_type": "temporal",
            "description": "...",
            "confidence": "high",
            "implications": ["..."]
        }}
    ],
    "uncertainties": ["uncertainty 1"],
    "follow_up_queries": [
        {{"tool": "search_news", "args": {{"keywords": "...", "country_code": "..."}}, "reason": "..."}}
    ]
}}
"""
    
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        HumanMessage(content=analysis_prompt),
    ]
    
    response = await llm.ainvoke(messages)
    
    try:
        # Extract thinking block if present
        thinking, main_response = _extract_thinking_block(response.content)
        
        analysis_text = main_response
        if "```json" in analysis_text:
            analysis_text = analysis_text.split("```json")[1].split("```")[0]
        elif "```" in analysis_text:
            analysis_text = analysis_text.split("```")[1].split("```")[0]
        
        analysis = json.loads(analysis_text.strip())
        
        # Extract thinking from JSON if not found in block
        analysis_thinking = analysis.get("thinking", "")
        if not thinking and analysis_thinking:
            thinking = analysis_thinking
        
        # Check if follow-up queries are needed
        follow_up = analysis.get("follow_up_queries", [])
        # Use REFLECTING phase for multi-step reasoning instead of going directly to CORRELATING
        next_phase = ResearchPhase.GATHERING.value if follow_up else ResearchPhase.REFLECTING.value
        
        logger.success(f"Analysis complete: {len(analysis.get('key_insights', []))} insights")
        
        # Log LLM response to reasoning file
        writer.log_llm_response(
            phase="analyzing",
            prompt_summary=f"Analyze {len(state.get('findings', []))} findings",
            response=json.dumps(analysis, indent=2),
        )
        
        # Log thinking/reasoning chain
        if thinking:
            writer.log_reasoning(
                phase="analyzing",
                step=state["iteration"] + 1,
                action="Chain of thought reasoning",
                details={"thinking": thinking},
            )
        
        # Add reasoning step
        reasoning_step = _add_reasoning_step(
            state,
            phase="analyzing",
            thought=thinking if thinking else "Analyzing patterns in collected evidence",
            action=f"Identified {len(analysis.get('key_insights', []))} insights",
            observation=f"Found {len(analysis.get('correlations', []))} correlations, {len(analysis.get('uncertainties', []))} uncertainties",
            conclusion="Analysis complete, proceeding to reflection" if not follow_up else f"Need {len(follow_up)} more queries",
            confidence=0.75,
        )
        
        # Log analysis details
        analysis_summary = []
        if analysis.get("key_insights"):
            analysis_summary.append("[bold]Key Insights:[/bold]")
            for insight in analysis["key_insights"][:5]:
                if isinstance(insight, dict):
                    analysis_summary.append(f"  â€¢ {insight.get('description', str(insight))}")
                else:
                    analysis_summary.append(f"  â€¢ {insight[:100]}..." if len(str(insight)) > 100 else f"  â€¢ {insight}")
        
        # Show hypothesis implications if present
        if analysis.get("hypothesis_implications"):
            analysis_summary.append(f"[bold]Hypothesis Implications:[/bold]")
            for hi in analysis["hypothesis_implications"][:3]:
                emoji = {"supporting": "âœ…", "contradicting": "âŒ", "neutral": "âž–"}.get(hi.get("evidence_type", "neutral"), "âž–")
                analysis_summary.append(f"  {emoji} [{hi.get('hypothesis_id')}] {hi.get('explanation', '')[:50]}...")
        
        if analysis.get("correlations"):
            analysis_summary.append(f"[bold]Correlations Found:[/bold] {len(analysis['correlations'])}")
        if analysis.get("uncertainties"):
            analysis_summary.append(f"[bold]Uncertainties:[/bold] {len(analysis['uncertainties'])}")
        if follow_up:
            analysis_summary.append(f"[bold]Follow-up Queries:[/bold] {len(follow_up)}")
            for q in follow_up[:3]:
                analysis_summary.append(f"  â€¢ {q.get('tool')}: {q.get('reason', 'No reason provided')[:50]}")
        
        if analysis_summary:
            logger.panel("\n".join(analysis_summary), title="ðŸ” Analysis Results", style="yellow")
        
        return {
            "key_insights": state.get("key_insights", []) + analysis.get("key_insights", []),
            "correlations": state.get("correlations", []) + analysis.get("correlations", []),
            "uncertainties": state.get("uncertainties", []) + analysis.get("uncertainties", []),
            "pending_queries": follow_up[:3],  # Limit follow-ups
            "reasoning_trace": state.get("reasoning_trace", []) + [reasoning_step],
            "reasoning_depth": state.get("reasoning_depth", 0) + 1,
            "chain_of_thought": state.get("chain_of_thought", []) + ([thinking] if thinking else []),
            "current_phase": next_phase,
            "iteration": state["iteration"] + 1,
            "last_updated": datetime.utcnow().isoformat(),
            "messages": state["messages"] + [
                AIMessage(content=f"Analysis: {json.dumps(analysis, indent=2)}"),
            ],
        }
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse analysis: {e}")
        return {
            "current_phase": ResearchPhase.SYNTHESIZING.value,
            "iteration": state["iteration"] + 1,
        }


# =============================================================================
# Correlation Node  
# =============================================================================


async def correlate_findings(
    state: AgentState,
    llm: BaseChatModel,
) -> dict[str, Any]:
    """
    Find correlations between findings from different sources.
    
    This node specifically looks for connections between news,
    satellite data, and connectivity information.
    """
    log_agent_step(state["iteration"] + 1, "Correlating multi-source data")
    
    # Log to reasoning file
    writer = get_output_writer()
    writer.log_reasoning(
        phase="correlating",
        step=state["iteration"] + 1,
        action="Finding correlations between multi-source data",
        details={"findings_count": len(state.get("findings", []))},
    )
    
    findings = state.get("findings", [])
    
    # Group findings by type
    by_type = {}
    for i, f in enumerate(findings):
        ftype = f.get("source_type", "unknown")
        if ftype not in by_type:
            by_type[ftype] = []
        by_type[ftype].append({"index": i, **f})
    
    correlation_prompt = f"""
You are correlating intelligence from multiple sources to find connections.

## Findings by Source Type
{json.dumps(by_type, indent=2)}

## Task Context
{state["task"]}

Look for:
1. **Temporal correlations**: Events happening around the same time
2. **Geospatial correlations**: Events in the same location from different sources
3. **Causal correlations**: One event potentially causing another
4. **Pattern correlations**: Similar patterns across different data types

For each correlation found, explain the connection and its implications.

Respond as JSON:
{{
    "correlations": [
        {{
            "finding_ids": [1, 15, 22],
            "correlation_type": "geospatial-temporal",
            "description": "Thermal anomalies detected at X coincide with news reports of Y",
            "confidence": "high",
            "implications": ["Military activity likely", "Infrastructure damage probable"]
        }}
    ],
    "synthesis_notes": "Overall pattern suggests..."
}}
"""
    
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        HumanMessage(content=correlation_prompt),
    ]
    
    response = await llm.ainvoke(messages)
    
    try:
        corr_text = response.content
        if "```json" in corr_text:
            corr_text = corr_text.split("```json")[1].split("```")[0]
        elif "```" in corr_text:
            corr_text = corr_text.split("```")[1].split("```")[0]
        
        correlations = json.loads(corr_text.strip())
        
        logger.success(f"Found {len(correlations.get('correlations', []))} correlations")
        
        # Log LLM response to reasoning file
        writer.log_llm_response(
            phase="correlating",
            prompt_summary="Find correlations between multi-source intelligence",
            response=json.dumps(correlations, indent=2),
        )
        
        # Log correlation details
        corr_summary = []
        for corr in correlations.get("correlations", [])[:5]:
            corr_type = corr.get("correlation_type", "unknown")
            desc = corr.get("description", "No description")[:80]
            confidence = corr.get("confidence", "unknown")
            corr_summary.append(f"[bold]{corr_type}[/bold] ({confidence})")
            corr_summary.append(f"  {desc}...")
        
        if correlations.get("synthesis_notes"):
            corr_summary.append(f"\n[bold]Synthesis:[/bold] {correlations['synthesis_notes'][:150]}...")
        
        if corr_summary:
            logger.panel("\n".join(corr_summary), title="ðŸ”— Correlations Found", style="magenta")
        
        # Add reasoning step for correlation
        reasoning_step = _add_reasoning_step(
            state,
            phase="correlating",
            thought="Looking for connections across different data sources",
            action=f"Found {len(correlations.get('correlations', []))} correlations",
            observation=correlations.get("synthesis_notes", "No synthesis notes"),
            conclusion="Ready for verification before final synthesis",
            confidence=0.8,
        )
        
        return {
            "correlations": state.get("correlations", []) + correlations.get("correlations", []),
            "key_insights": state.get("key_insights", []) + [correlations.get("synthesis_notes", "")],
            "reasoning_trace": state.get("reasoning_trace", []) + [reasoning_step],
            "reasoning_depth": state.get("reasoning_depth", 0) + 1,
            "current_phase": ResearchPhase.VERIFYING.value,  # Go to verification before synthesis
            "iteration": state["iteration"] + 1,
            "last_updated": datetime.utcnow().isoformat(),
        }
    except json.JSONDecodeError:
        return {
            "current_phase": ResearchPhase.VERIFYING.value,  # Still verify even on error
            "iteration": state["iteration"] + 1,
        }


# =============================================================================
# Synthesis Node
# =============================================================================


async def synthesize_report(
    state: AgentState,
    llm: BaseChatModel,
) -> dict[str, Any]:
    """
    Synthesize all findings into a final intelligence report.
    
    This node creates the executive summary, detailed report,
    and recommendations. Uses verified insights and correlations
    from the multi-step reasoning process.
    """
    log_agent_step(state["iteration"] + 1, "Synthesizing final report")
    
    # Log to reasoning file
    writer = get_output_writer()
    
    # Use verified data if available, otherwise fall back to original
    insights_to_use = state.get("verified_insights") or state.get("key_insights", [])
    correlations_to_use = state.get("verified_correlations") or state.get("correlations", [])
    
    writer.log_reasoning(
        phase="synthesizing",
        step=state["iteration"] + 1,
        action="Creating final intelligence report from verified findings",
        details={
            "verified_insights_count": len(state.get("verified_insights", [])),
            "verified_correlations_count": len(state.get("verified_correlations", [])),
            "hypotheses_count": len(state.get("hypotheses", [])),
            "reasoning_depth": state.get("reasoning_depth", 0),
            "reflection_iterations": state.get("reflection_iterations", 0),
        },
    )
    
    # Build hypothesis summary
    hypotheses_summary = ""
    if state.get("hypotheses"):
        hyp_lines = []
        for h in state["hypotheses"]:
            status_emoji = {
                "supported": "âœ…",
                "refuted": "âŒ",
                "investigating": "ðŸ”",
                "inconclusive": "â“",
                "proposed": "ðŸ“",
            }.get(h.get("status", "proposed"), "ðŸ“")
            hyp_lines.append(f"- {status_emoji} **{h['id']}**: {h['statement']} (confidence: {h.get('confidence', 0):.0%})")
        hypotheses_summary = "\n## Hypothesis Results\n" + "\n".join(hyp_lines)
    
    # Build reflection summary
    reflection_summary = ""
    if state.get("reflection_notes"):
        critical_notes = [n for n in state["reflection_notes"] if n.get("severity") == "critical"]
        if critical_notes:
            reflection_summary = "\n## Critical Reflection Notes\n" + "\n".join([f"- {n['content']}" for n in critical_notes[:3]])
    
    synthesis_prompt = f"""
{ENHANCED_SYNTHESIZER_PROMPT}

## Original Task
{state["task"]}

## Research Plan
{json.dumps(state.get("research_plan", {}), indent=2)}
{hypotheses_summary}

## Verified Key Insights
{json.dumps(insights_to_use, indent=2)}

## Verified Correlations
{json.dumps(correlations_to_use, indent=2)}

## Uncertainties
{json.dumps(state.get("uncertainties", []), indent=2)}
{reflection_summary}

## Reasoning Process Summary
- Reasoning depth: {state.get("reasoning_depth", 0)} steps
- Reflection iterations: {state.get("reflection_iterations", 0)}
- Verification results: {len(state.get("verification_results", []))} items verified

## Data Sources Used
- Queries executed: {len(state.get("executed_queries", []))}
- Findings collected: {len(state.get("findings", []))}

Create a comprehensive intelligence report as JSON:
{{
    "executive_summary": "2-3 sentence summary of key findings",
    "detailed_report": "Multi-paragraph detailed analysis in markdown format",
    "recommendations": ["recommendation 1", "recommendation 2"],
    "confidence_assessment": "Overall confidence level and explanation",
    "methodology_note": "Brief note on the multi-step reasoning process used"
}}
"""
    
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        HumanMessage(content=synthesis_prompt),
    ]
    
    response = await llm.ainvoke(messages)
    
    try:
        report_text = response.content
        if "```json" in report_text:
            report_text = report_text.split("```json")[1].split("```")[0]
        elif "```" in report_text:
            report_text = report_text.split("```")[1].split("```")[0]
        
        report = json.loads(report_text.strip())
        
        logger.success("Final report synthesized")
        
        # Log LLM response to reasoning file
        writer.log_llm_response(
            phase="synthesizing",
            prompt_summary="Synthesize final intelligence report",
            response=json.dumps(report, indent=2),
        )
        
        # Log the executive summary
        if report.get("executive_summary"):
            logger.panel(
                report["executive_summary"],
                title="ðŸ“Š Executive Summary",
                style="green"
            )
        
        # Log recommendations
        if report.get("recommendations"):
            rec_lines = ["[bold]Recommendations:[/bold]"]
            for rec in report["recommendations"][:5]:
                rec_lines.append(f"  â€¢ {rec}")
            logger.panel("\n".join(rec_lines), title="ðŸ’¡ Recommendations", style="cyan")
        
        # Log confidence assessment
        if report.get("confidence_assessment"):
            logger.thinking(f"Confidence: {report['confidence_assessment'][:150]}...")
        
        return {
            "executive_summary": report.get("executive_summary"),
            "detailed_report": report.get("detailed_report"),
            "recommendations": report.get("recommendations", []),
            "confidence_assessment": report.get("confidence_assessment"),
            "current_phase": ResearchPhase.COMPLETE.value,
            "iteration": state["iteration"] + 1,
            "last_updated": datetime.utcnow().isoformat(),
        }
    except json.JSONDecodeError as e:
        # Return raw content if JSON parsing fails
        return {
            "detailed_report": response.content,
            "current_phase": ResearchPhase.COMPLETE.value,
            "iteration": state["iteration"] + 1,
        }


# =============================================================================
# Router Function
# =============================================================================


def route_next_step(state: AgentState) -> Literal[
    "decompose", "hypothesize", "gather", "analyze", "reflect", "correlate", "verify", "synthesize", "end"
]:
    """
    Determine the next node based on current state.
    
    This is used as a conditional edge in the graph.
    Supports both traditional and multi-step reasoning phases.
    """
    phase = state.get("current_phase", ResearchPhase.PLANNING.value)
    iteration = state.get("iteration", 0)
    max_iter = state.get("max_iterations", 10)
    
    # Safety check for max iterations
    if iteration >= max_iter:
        logger.warning(f"Max iterations ({max_iter}) reached, forcing synthesis")
        return "synthesize"
    
    # Check for errors
    if state.get("error"):
        return "end"
    
    # Route based on phase (including new multi-step reasoning phases)
    if phase == ResearchPhase.DECOMPOSING.value:
        return "decompose"
    elif phase == ResearchPhase.HYPOTHESIZING.value:
        return "hypothesize"
    elif phase == ResearchPhase.GATHERING.value:
        return "gather"
    elif phase == ResearchPhase.ANALYZING.value:
        return "analyze"
    elif phase == ResearchPhase.REFLECTING.value:
        return "reflect"
    elif phase == ResearchPhase.CORRELATING.value:
        return "correlate"
    elif phase == ResearchPhase.VERIFYING.value:
        return "verify"
    elif phase == ResearchPhase.SYNTHESIZING.value:
        return "synthesize"
    elif phase == ResearchPhase.COMPLETE.value:
        return "end"
    else:
        return "end"
